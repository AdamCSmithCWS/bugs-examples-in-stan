# Aspirin: Shrinkage (or "borrowing strength") via hierarchical modeling (aspirin)

```{r aspirin_setup,message=FALSE}
library("tidyverse")
library("rstan")
```


The following data come from a meta-analysis of heart attack data.  Each observation is the results of a study of survivorship following a heart attack (myocardial infarction). In each study, some victims were given aspirin immediately following their heart attack, while some vicitims were not.  The observed values of y are the differences in mean survivorship observed in each study, with the other piece of data, the standard deviations, reflecting the relative sizes of the two groups in each study (i.e., although the data are binomial, given the large number of observations per study a normal approximation is valid and reduces each study's data to the observed treatement effect and a standard deviation).  The goal of the meta-analysis is to synthesize the six studies, so as to arrive at an overall conclusion regarding the effects of aspirin on survivorship following a heart attack.

This is an extremely simple example of hierarchical modeling.  Via the exchangeability assumption (i.e., the study-specific means have a common prior), the studies "borrow strength" from one another, introducing some bias (each study's mean qi is shrunk back towards the common mean), but with the benefit of gaining precision (smaller variance).  We also gain a better estimate of the overall effect of aspirin on survivorship after heart attack than we would get from naively pooling the studies.

These data and the meta-analysis is discussed at length in @Draper1992a.

$$
\begin{aligned}[t]
y_i &\sim \mathsf{Normal}(\theta_i, s_i) , \\
\theta_i &\sim \mathsf{Normal}(\mu, \tau) ,
\end{aligned}
$$
where $y_i$ is the mean of each study, and $s_i$ is the
standard deviation for each study.
$$
\begin{aligned}[t]
\mu &\sim \mathsf{Normal}(\bar{y}, 10 s_y) , \\
\tau &\sim \mathsf{HalfCauchy}(0, 5 s_y) ,
\end{aligned}
$$
where $\bar{y}$ is the mean of $y$, and $s_y$ is the standard deviation of $y$.

## Centered Parameterization

```{r aspirin_mod,results='hide',cache.extra=tools::md5sum("stan/aspirin.stan")}
aspirin_mod <- stan_model("stan/aspirin.stan")
```

```{r results='asis'}
aspirin_mod
```

```{r aspirin}
aspirin <- 
  tibble(y = c(2.77, 2.50, 1.84, 2.56, 2.31, -1.15),
         sd = c(1.65, 1.31, 2.34, 1.67, 1.98, 0.90))
```

```{r aspirin_data}
aspirin_data <- within(list(), {
  y <- aspirin$y
  N <- nrow(aspirin)
  s <- aspirin$sd
  mu_loc <- mean(y)
  mu_scale <- 5 * sd(y)
  tau_scale <- 2.5 * sd(y)
  tau_df <- 4
})
```


```{r results='hide'}
aspirin_fit <- sampling(aspirin_mod, data = aspirin_data)
```
```{r}
aspirin_fit
```


Note that this model is likely to produce divergent transitions.
When the data are few, there 


## Non-centered parameterization

For few data, when there are not many groups, or when inter-group variation is high, it can be more efficient to use the non-centered parameterization. See @Stan2016a [p. 331] and @BetancourtGirolami2013a for a more detailed discussion of this.

The non-centered parameterization is
$$
\begin{aligned}[t]
\theta_i^* &\sim \mathsf{Normal}(0, 1) , \\
\theta_i &= \tau \theta^*_i + \mu .
\end{aligned}
$$

```{r aspirin_mod2,results='hide',cache.extra=tools::md5sum("stan/aspirin.stan")}
aspirin_mod2 <- stan_model("stan/aspirin2.stan")
```

```{r results='asis'}
aspirin_mod2
```

```{r aspirin_fit2,results='hide'}
aspirin_fit2 <- sampling(aspirin_mod2, data = aspirin_data,
                        control = list(adapt_delta = 0.99))
```
```{r}
aspirin_fit2
```

