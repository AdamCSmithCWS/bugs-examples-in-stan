---
title: "Unidentified: over-parameterization of normal mean"
author: Simon Jackman and Jeffrey Arnold
---

Original BUGS code and text by Simon Jackman; translated to Stan by Jeffrey Arnold.

The following example illustrates the need for caution in diagnosing convergence, and is based on an example appearing in Carlin and Louis' Bayes and Empirical Bayes Methods for Data Analysis, 2nd edition, p174.

Consider a model for the mean as an additive sum of two parameters: e.g.,
$y ~ N(q_1 + q_2, 1)$.   The data are not informative about $q_1$ and $q_2$ , but are informative about $m = q_1 + q_2$  and the likelihood function for the two unidentified parameters has a ridge along the locus of points
$$
\left\{ q_1, q_2 : \bar{y} = q_1 + q_2 \right\} ,
$$
where $\bar{y}$ is the mean of the observed data.

In the Bayesian approach, we are obliged to specify priors over the model parameters.  Proper priors ensure unimodal posteriors for $q_1$ and $q_2$, and can be used to the sample from the posterior for this problem.  But as Carlin and Louis show (see their Q25, p191), we need to be careful with models of this type.  The posteriors for theta are not identical to the prior (the posterior standard deviations are 7.05, while the prior standard deviations used below are 10), suggesting that the data are somewhat informative about both theta parameters, when this is not the case.  An inexperienced user of Markov chain Monte Carlo methods might fail to recognize that the q parameters are not identified, and naively report the posterior summaries for theta generated by the software.  On the other hand, note that the identified parameter $m = q_1 + q_2$  is well behaved.

The original BUGS model
```
model{

	## loop over observations
	for (i in 1:1){
		y[i] ~ dnorm(mu,1.0);  ## known precision
	}
	mu <- theta[1] + theta[2]

	## priors
	#theta[1] ~ dnorm(0.0, 0.01);     ## this form is not efficient
	#theta[2] ~ dnorm(0.0, 0.01);     ## vis-a-vis en bloc approach below

	theta[1:2] ~ dmnorm(b0[],B0[,])   ## en bloc updating for theta
	b0[1] <- 0 b0[2] <- 0
	B0[1,1] <- .01 B0[2,2] <- .01
	B0[1,2] <- 0 B0[2,1] <- 0
}
```

```{r}
library("rstan")
mod_unidentified <- stan_model("stan/unidentified.stan")
```

Use very large scales for this; though the behavior is still present with
weakly informative scales.
```{r}
data_unidentified <- list(
  y = 0,
  theta_mean = rep(0, 2),
  theta_scale = rep(100, 2)
)
```
```{r results='hide',message=FALSE}
fit_unidentified <- sampling(mod_unidentified, data = data_unidentified,
                             refresh = -1)
```
```{r}
fit_unidentified
```

