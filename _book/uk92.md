
# House of Commons elections: modeling with the multivariate Student-$t$ density {#uk92}



```r
library("tidyverse")
library("rstan")
```

The data for this example consist of constituency vote proportions from the 1992 United Kingdom House of Commons election.
These data come from @KatzKing1999a, were re-analyzed @TomzTuckerWittenberg2002a.[^uk92-source] 
This data is included in the **pscl** package as `UKHouseOfCommons`:

```r
(data("UKHouseOfCommons", package = "pscl"))
#> [1] "UKHouseOfCommons"
glimpse(UKHouseOfCommons)
#> Observations: 521
#> Variables: 12
#> $ constituency <chr> "Barrow & Furness", "Berwick-upon-Tweed", "Bishop...
#> $ county       <chr> "Cumbria", "Northumberland", "Durham", "Durham", ...
#> $ y1           <dbl> 1.3286, -0.3032, 0.5598, 0.0978, 1.7351, 0.4546, ...
#> $ y2           <dbl> 1.473, -0.663, 1.011, 0.909, 1.851, 1.925, 0.108,...
#> $ y1lag        <dbl> 1.1820, -0.5689, 0.7052, -0.4139, 1.5507, 0.0408,...
#> $ y2lag        <dbl> 1.0142, -1.0906, 1.0258, 0.3037, 1.6453, 1.4702, ...
#> $ coninc       <int> 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0...
#> $ labinc       <int> 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1...
#> $ libinc       <int> 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0...
#> $ v1           <dbl> 0.413, 0.328, 0.318, 0.240, 0.435, 0.167, 0.533, ...
#> $ v2           <dbl> 0.477, 0.229, 0.500, 0.541, 0.488, 0.727, 0.246, ...
#> $ v3           <dbl> 0.1094, 0.4437, 0.1818, 0.2181, 0.0767, 0.1061, 0...
```

The data consist of the vote proportions for 522 constituencies, for the three major UK parties: the Labor party, the Conservative Party, and the Liberal-Alliance.
Instead of working with the vote proportions directly, we will work with log-odds ratios.
This is common in the analysis of multinomial or "compositional" data [@Aitchison1982a].
The column `y1` is the log-odds of Conservative to the Liberal-Democratic vote share, while `y2` is the log-odds of Labor to the Liberal-Democratic vote share.


Let $y_{i,k}$, $k \in \{1, 2\}$, $i \in 1, \dots, N$ be the log-odds ratio vote share in constituency $i$.
@KatzKing1999a noted that the distribution of the log-odds ratios appear to be heavy-tailed relative to the normal.
Thus, like them, we will model the data with a multivariate Student's $t$ distribution with unknown degrees of freedom ($\nu$),
$$
\begin{aligned}[t]
y_i &\sim \mathsf{StudentT}(\nu, \alpha + x' \beta, \Sigma) & i \in 1, \dots, N,
\end{aligned}
$$

For identifiction, as in a logit regression, either the intercept or scale must be fixed. In this case, $\Sigma$ is a correlation matrix.

Weakly informative priors are used for the regression parameters. 
The degrees of freedom of the multivariate Student t distribution is a parameter, and given a weakly informative Gamma distribution that puts most of the prior density between 3 and 40 [@JuarezSteel2010a],
$$
\begin{aligned}[t]
\alpha &\sim  \mathsf{Normal}(0, 10) , \\
\beta_p &\sim \mathsf{Normal}(0, 2.5), & p \in 1, \dots, P , \\
\Sigma &\sim \mathsf{LkjCorr}(\eta) , \\
\nu &\sim \mathsf{Gamma}(2, 0.1) .
\end{aligned}
$$


```r
(data("UKHouseOfCommons", package = "pscl"))
#> [1] "UKHouseOfCommons"
glimpse(UKHouseOfCommons)
#> Observations: 521
#> Variables: 12
#> $ constituency <chr> "Barrow & Furness", "Berwick-upon-Tweed", "Bishop...
#> $ county       <chr> "Cumbria", "Northumberland", "Durham", "Durham", ...
#> $ y1           <dbl> 1.3286, -0.3032, 0.5598, 0.0978, 1.7351, 0.4546, ...
#> $ y2           <dbl> 1.473, -0.663, 1.011, 0.909, 1.851, 1.925, 0.108,...
#> $ y1lag        <dbl> 1.1820, -0.5689, 0.7052, -0.4139, 1.5507, 0.0408,...
#> $ y2lag        <dbl> 1.0142, -1.0906, 1.0258, 0.3037, 1.6453, 1.4702, ...
#> $ coninc       <int> 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0...
#> $ labinc       <int> 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1...
#> $ libinc       <int> 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0...
#> $ v1           <dbl> 0.413, 0.328, 0.318, 0.240, 0.435, 0.167, 0.533, ...
#> $ v2           <dbl> 0.477, 0.229, 0.500, 0.541, 0.488, 0.727, 0.246, ...
#> $ v3           <dbl> 0.1094, 0.4437, 0.1818, 0.2181, 0.0767, 0.1061, 0...
```


```r
uk92_data <- within(list(), {
  y <- as.matrix(dplyr::select(UKHouseOfCommons, y1, y2))
  X <- model.matrix(~ 0 + y1lag + y2lag + coninc + labinc + libinc, data = UKHouseOfCommons) %>% scale()
  N <- nrow(y)
  K <- ncol(y)
  P <- ncol(X)
  alpha_loc <- rep(0, K)
  alpha_scale <- rep(10, K)
  beta_loc <- matrix(0, K, P)
  beta_scale <- matrix(2.5, K, P)
  Sigma_corr_shape <- 2
  Sigma_scale_scale <- 5
})
```


```r
uk92_mod <- stan_model("stan/uk92.stan")
#> hash mismatch so recompiling; make sure Stan code ends with a blank line
```
<pre>
  <code class="stan">data {
  // multivariate outcome
  int<lower = 1> N;
  int<lower = 2> K;
  vector[K] y[N];
  // covariates
  int<lower = 0> P;
  vector[P] X[N];
  // prior
  vector[K] alpha_loc;
  vector<lower = 0.>[K] alpha_scale;
  vector[P] beta_loc[K];
  vector<lower = 0.>[P] beta_scale[K];
  real<lower = 0.> Sigma_corr_shape;
  real<lower = 0.> Sigma_scale_scale;
}
parameters {
  // regression intercept
  vector[K] alpha;
  // regression coefficients
  vector[P] beta[K];
  // Cholesky factor of the correlation matrix
  cholesky_factor_corr[K] Sigma_corr_L;
  vector<lower = 0.>[K] Sigma_scale;
  // student-T degrees of freedom
  real<lower = 2.> nu;
}
transformed parameters {
  vector[K] mu[N];
  matrix[K, K] Sigma;
  // covariance matrix
  Sigma = crossprod(diag_pre_multiply(Sigma_scale, Sigma_corr_L));
  for (i in 1:N) {
    for (k in 1:K) {
      mu[i, k] = alpha[k] + dot_product(X[i], beta[k]);
    }
  }
}
model {
  for (k in 1:K) {
    alpha[k] ~ normal(alpha_loc[k], alpha_scale[k]);
    beta[k] ~ normal(beta_loc[k], beta_scale[k]);
  }
  nu ~ gamma(2, 0.1);
  Sigma_scale ~ cauchy(0., Sigma_scale_scale);
  Sigma_corr_L ~ lkj_corr_cholesky(Sigma_corr_shape);
  y ~ multi_student_t(nu, mu, Sigma);
}</code>
</pre>

Fit the model in Stan.

```r
uk92_fit <- sampling(uk92_mod, data = uk92_data, chains = 1)
#> The following numerical problems occurred the indicated number of times on chain 1
#>                                                                                                      count
#> Exception thrown at line 47: multi_student_t: Scale parameter is not symmetric. Scale parameter[1,2]     4
#> Exception thrown at line 47: multi_student_t: LDLT_Factor of scale parameter is not positive definit     3
#> When a numerical problem occurs, the Hamiltonian proposal gets rejected.
#> See http://mc-stan.org/misc/warnings.html#exception-hamiltonian-proposal-rejected
#> If the number in the 'count' column is small, there is no need to ask about this message on stan-users.
```

```r
summary(uk92_fit, par = c("nu", "alpha", "beta", "Sigma"))$summary
#>               mean  se_mean      sd    2.5%     25%     50%      75%
#> nu          4.5903 2.08e-02 0.65619  3.5135  4.1174  4.5473  4.98862
#> alpha[1]    0.9294 3.10e-04 0.00943  0.9102  0.9234  0.9293  0.93595
#> alpha[2]    0.6089 4.21e-04 0.01259  0.5833  0.6007  0.6085  0.61726
#> beta[1,1]   0.3607 5.14e-04 0.01341  0.3339  0.3521  0.3607  0.36925
#> beta[1,2]   0.1646 5.33e-04 0.01336  0.1399  0.1548  0.1646  0.17379
#> beta[1,3]   0.0467 5.24e-04 0.01354  0.0209  0.0372  0.0465  0.05617
#> beta[1,4]  -0.0627 7.20e-04 0.01527 -0.0927 -0.0735 -0.0623 -0.05244
#> beta[1,5]  -0.0151 5.64e-04 0.01574 -0.0475 -0.0258 -0.0142 -0.00445
#> beta[2,1]  -0.0213 6.90e-04 0.01711 -0.0561 -0.0325 -0.0208 -0.00942
#> beta[2,2]   1.0402 7.22e-04 0.01803  1.0076  1.0273  1.0400  1.05287
#> beta[2,3]   0.0719 7.18e-04 0.01860  0.0364  0.0584  0.0714  0.08469
#> beta[2,4]  -0.0551 9.66e-04 0.02084 -0.0974 -0.0683 -0.0553 -0.04068
#> beta[2,5]  -0.0183 7.47e-04 0.02181 -0.0641 -0.0332 -0.0171 -0.00260
#> Sigma[1,1]  0.0322 8.82e-05 0.00279  0.0272  0.0305  0.0321  0.03391
#> Sigma[1,2]  0.0373 1.07e-04 0.00339  0.0310  0.0350  0.0372  0.03948
#> Sigma[2,1]  0.0373 1.07e-04 0.00339  0.0310  0.0350  0.0372  0.03948
#> Sigma[2,2]  0.0566 1.57e-04 0.00495  0.0475  0.0531  0.0564  0.05974
#>              97.5% n_eff  Rhat
#> nu          6.0501  1000 1.000
#> alpha[1]    0.9480   927 0.999
#> alpha[2]    0.6335   894 1.000
#> beta[1,1]   0.3871   680 1.008
#> beta[1,2]   0.1921   628 1.005
#> beta[1,3]   0.0721   668 1.000
#> beta[1,4]  -0.0340   450 1.005
#> beta[1,5]   0.0128   780 1.000
#> beta[2,1]   0.0122   614 1.010
#> beta[2,2]   1.0751   623 1.006
#> beta[2,3]   0.1083   670 1.000
#> beta[2,4]  -0.0171   466 1.008
#> beta[2,5]   0.0196   852 1.001
#> Sigma[1,1]  0.0386  1000 1.001
#> Sigma[1,2]  0.0446  1000 1.001
#> Sigma[2,1]  0.0446  1000 1.001
#> Sigma[2,2]  0.0668  1000 1.001
```

## Questions

- Given this model replicate some of the results in @KatzKing1999a.
- Model the data using a multivariate normal model instead. How do the results differ? Which fits the data better? What does the value of $\nu$ from the multivariate Student t model tell you about the plausibility of the multivariate normal distribution?
- @TomzTuckerWittenberg2002a suggest using seemingly unrelated regressions (SUR). Model the data with SUR. How does it compare in results and speed?
- Could you model this using a multinomial model with the data provided? What data would you need?

[^uk92-source]: Example derived from Simon Jackman, "House of Commons elections: modeling with the multivariate t density." *BUGS Examples* [URL](https://web-beta.archive.org/web/20070724034125/http://jackman.stanford.edu/mcmc/92.odc). Some language copied from the original.
