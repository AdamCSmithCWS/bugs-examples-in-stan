Generalized Beetles: generalizing link functions for binomial GLMs

Model description:

GLMs rely on link functions, linking the linear predictors and the response probability, pi. Logit and probit are perhaps the most familiar link functions,
mapping from the unit probability interval to the real line using the inverse CDFs of the logistic and standard Normal distributions, respectively. The logit and probit link functions have the interesting property that they are symmetric
about pi = 0.5, and guarantee the effects of xi  on pi to be greatest when pi  = 0.5. To see this, recall that in GLMs for binomial data the effects of xi on pi are not constant, but vary over pi.  For logit and probit, with link functions symmetric around zero, the effect of xi  on pi  is at its greatest when f (xi b) is its maximum, which for logit and probit occurs at xi b = 0. In dose-response studies, this means that responsiveness to dose is at its greatest when subjects are on the cusp of a response, at, that is, when E(pi) = 0.5.  In a study of voter turnout, ordinary logit or probit is estimated subject to the constraint that the effects of the covariates are at their greatest for citizens who are indifferent between turning out and abstaining (e.g., Nagler, 1994). Furthermore, for logit/probit, these marginal effects diminish in magnitude symmetrically as we move away from E(pi) = 0.5; this symmetry follows from the symmetry of the logistic and normal PDFs/CDFs.

One can easily envisage situations where the researcher would not want to impose these features of the logit/probit link functions on their data. In many settings, knowledge of exactly where the marginal impact of the covariates is maximized is of tremendous practical importance, with implications for targeting policy interventions, resource allocation, and so on. For example, how to distribute resources for educational or health improvements? Given that the effects of interventions are not constant across a set of baseline probabilities,
knowing where proposed interventions are likely to have bigger or smaller effects is valuable information for policy-makers. As we have seen, logit/probit constrain these effects to be at their greatest at E(pi) = .5, via their symmetric ‘‘S’’-shaped link functions. Ceteris paribus we would prefer to estimate the shape of the link function from the data.

A relatively straightforward way to let the data be informative as to the shape of the link function is via a simple one-parameter transformation of the logit link (Prentice, 1976): pi = {1/[1 + exp(-xi b) ] }m, where m > 0 is a parameter that skews the logit link. The standard logit model is a special case, where m = 1.

Estimating m and b by maximum likelihood is relatively straightforward, although there is little reason to believe the frequentist sampling distribution for m is likely to be well approximated by the normal in a finite sample. Notice that m enters the model in a highly non-linear fashion, and that different ranges of m imply quite different relationships between the linear predictors and pi.  In Bayesian terms, we can reasonably expect the posterior
density of m to be non-normal, and probably log-normal. Likewise, the posterior densities of related quantities of interest such as the LD50 could well be non-normal. Inferences for these quantities could well be misleading if we were to rely only on point estimates and asymptotic normal approximations; instead, a Bayesian approach via MCMC offers a way for us to obtain arbitrarily precise approximations to the posterior densities of these quantities.

To demonstrate the use of MCMC methods in this context, I use the famous beetles data of Bliss (1935); these data have been extensively used by statisticians in studies generalized link functions (e.g., Prentice, 1976; Stukel, 1988), and are used by Spiegelhalter et al. (1996) to demonstrate how BUGS handles GLMs for binomial data. Carlin and Louis (1996) use these data in an MCMC implementation of the one-parameter generalization used here; they
made use of re-parameterizations and problem-specific computer programming to handle the non-conjugacies introduced via the skew parameter m. Here I show how WinBUGS can handle this problem relatively simply.

The implementation in WinBUGS exploits the software’s capacities for dealing with nonconjugacies via Metropolis methods and slice-sampling. I employ diffuse Normal priors for the slope and intercept parameters, which are updated via Metropolis methods.  I use a Gamma prior on m, with a prior mean of 1.0 (corresponding to the standard logit model), and a prior standard deviation of 2. Adopting the parameterization of the Gamma distribution in WinBUGS, this corresponds to a Gamma (.25, .25) density; contrast the parameterization in Carlin and Louis (1996, 178), where the same prior is represented
as a Gamma (.25, 4) density. With the restriction m > 0 inherent in the Gamma prior and the non-conjugacy, WinBUGS defaults to slice sampling (Neal, 1997) to generate draws from the conditional distribution for m.



References:

Bliss, C. I. 1935. ‘‘The calculation of the dosage-mortality curve.’’ Annals of Applied Biology
22:134--167.

Carlin, Bradley P. and Thomas A. Louis. 1996. Bayes and Empirical Bayes Methods for Data
Analysis. London: Champman and Hall.

Nagler, Jonathan. 1994. ‘‘Scobit: an alternative estimator to logit and probit.’’ American
Journal of Political Science 38:230--55.

Neal, Radford M. 1997. Markov chain Monte Carlo methods based on ‘slicing’ the density
function. Technical Report No. 9722. Department of Statistics, University of Toronto.

Prentice, Ross L. 1976. ‘‘A Generalization of the Probit and Logit Methods for Dose Response
Curves.’’ Biometrics 32:761--768.

Spiegelhalter, D. J., A. Thomas, N. Best and W. R. Gilks. 1996. BUGS: Bayesian Inference
Using Gibbs Sampling, Version 0.5 (version ii). Cambridge, UK: MRC Biostatistics Unit.

Stukel, Thérése A. 1988. ‘‘Generalized Logistic Models.’’ Journal of the American Statistical
Association 83:426--431.



model
{
  for(i in 1:N) {
    r[i] ~ dbin(p[i],n[i])
    logit(w[i]) <- alpha.star + beta * (x[i] - mean(x[ ]))
    p[i] <- pow(w[i],m)
  }
	  ## auxilary quantities 
  kappa <- -(log(.5)/m)
  z <- -log(exp(kappa) - 1)
  ld50 <- (z-alpha)/beta               ## LD50
  pdot <- pow(1/(1+exp(-log(m))),m)    ## prob where max marginal effect
  alpha <- alpha.star - beta * mean(x[])
  
  ## priors
  beta ~ dnorm(0.0 ,0.001)
  alpha.star ~ dnorm(0.0, 0.001)
  m ~ dgamma(.25,.25);
}

Data:
list( x = c(1.6907, 1.7242, 1.7552, 1.7842, 1.8113, 1.8369, 1.8610, 1.8839),
		  n = c(59, 60, 62, 56, 63, 59, 62, 60),
		  r = c(6, 13, 18, 28, 52, 53, 61, 60), N = 8)
	
Initial Values:

list(alpha.star=-60, beta=40, m=1)

list(alpha.star=0,beta=0,m=.2)

Results:

	 node	 mean	 sd	 MC error	2.5%	median	97.5%	start	sample
	alpha	-107.3	22.97	1.225	-158.7	-105.4	-68.21	4001	20000
	beta	59.14	12.39	0.6566	38.19	58.02	86.86	4001	20000
	ld50	1.779	0.004551	1.622E-4	1.77	1.779	1.788	4001	20000
	m	0.3491	0.1411	0.008177	0.1733	0.3185	0.7242	4001	20000
	pdot	0.6336	0.04606	0.002618	0.5336	0.6361	0.7179	4001	20000
